\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage[margin=2.5cm]{geometry}

% Code listing configuration
\lstset{
    language=Python,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black},
    stringstyle=\color{orange},
    showstringspaces=false,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    numbersep=3pt,
    tabsize=4,
    captionpos=b,
    xleftmargin=0.3cm,
    xrightmargin=0.3cm
}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    pdftitle={Lab 1: Search Algorithms - AIF}
}

\begin{document}

% ============================================
% TITLE PAGE
% ============================================
\begin{titlepage}
    \centering
    \vspace*{2cm}
    {\LARGE\textbf{Artificial Intelligence Fundamentals}}\\[0.5cm]
    {\Large Lab 1: Implementation of Search Algorithms}\\[1.5cm]
    {\large Master in Artificial Intelligence}\\[0.3cm]
    {\large 2025--2026}\\[2cm]
    
    {\large\textbf{Authors:}}\\[0.3cm]
    {\large David Carballo Rodríguez}\\[0.2cm]
    {\large Antonio Vila Leis}\\[0.2cm]
    {\large Santiago Delgado Ferreiro}\\[1.5cm]
    
    {\large\textbf{Practice Group:} [Group Number]}\\[1.5cm]
    \vfill
    {\large October 2025}
\end{titlepage}

\tableofcontents
\newpage

% ============================================
% METHODS
% ============================================
\section{Methods}

\subsection{Formal Characterization of the Problem}

\subsubsection{State Representation}
A state is defined as $S = (x, y, o)$ where $x \in \{0, \ldots, N-1\}$ is the row coordinate, $y \in \{0, \ldots, M-1\}$ is the column coordinate, and $o \in \{0, 1, 2, 3, 4, 5, 6, 7\}$ is the robot orientation (0=North, 1=Northeast, 2=East, 3=Southeast, 4=South, 5=Southwest, 6=West, 7=Northwest). The state space has $|\mathcal{S}| = N \times M \times 8$ states.

\subsubsection{Set of Operators}
Three operators are available, always generated in fixed order:
\begin{enumerate}[itemsep=0.2em]
    \item \textbf{rotate\_right}: Effect $o' = (o + 1) \bmod 8$, Cost = 1
    \item \textbf{move}: Effect $(x', y') = (x + \Delta x, y + \Delta y)$, Cost = hardness$(x', y')$. Precondition: destination within map bounds.
    \item \textbf{rotate\_left}: Effect $o' = (o - 1) \bmod 8$, Cost = 1
\end{enumerate}

For each orientation, displacements are: 0:(-1,0), 1:(-1,1), 2:(0,1), 3:(1,1), 4:(1,0), 5:(1,-1), 6:(0,-1), 7:(-1,-1).

\subsubsection{Transition Model}
Function $\text{successors}(s, M)$ generates valid successors in R→M→L order. DFS reverses this order on the stack so expansion follows the same R→M→L sequence.

\subsubsection{Goal Test}
$$\text{is\_goal}(s, s_{\text{goal}}) = \begin{cases}
(x = x_{\text{goal}}) \land (y = y_{\text{goal}}) & \text{if } o_{\text{goal}} = 8 \\
s = s_{\text{goal}} & \text{otherwise}
\end{cases}$$

\subsubsection{Cost Function}
Path cost: $g(n) = \sum_{i=1}^{d} c(\text{action}_i)$ where rotations cost 1 and moves cost the destination cell's hardness.

\subsection{Analysis of Blind Search Methods}

\subsubsection{Breadth-First Search (BFS)}

\paragraph{Algorithm Description.}
BFS explores the state space level by level, guaranteeing to find the solution with minimum depth. It uses a FIFO queue (\texttt{collections.deque}) to manage the frontier.

\paragraph{Implementation Details.}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Data structures:} FIFO queue (deque), explored set, frontier\_set for $O(1)$ duplicate checks
    \item \textbf{Successor order:} Uses shared \texttt{successors()} function (R→M→L order)
    \item \textbf{Goal detection:} Halts immediately when goal is generated
\end{itemize}

\paragraph{Theoretical Properties.}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Completeness:} Yes (finite state space with duplicate detection)
    \item \textbf{Optimality:} Finds minimum depth, but NOT minimum cost (non-uniform costs)
    \item \textbf{Time complexity:} $O(b^d)$ where $b \leq 3$ (branching factor)
    \item \textbf{Space complexity:} $O(b^d)$ --- main limitation for large problems
\end{itemize}

\paragraph{Justification for this problem.}
BFS is preferable to DFS due to guaranteed completeness and shorter solutions, though it doesn't guarantee minimum cost given heterogeneous action costs.

\subsubsection{Depth-First Search (DFS)}

\paragraph{Algorithm Description.}
DFS explores each branch to maximum depth before backtracking. Uses a LIFO stack (Python list).

\paragraph{Implementation Details.}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Data structures:} LIFO stack (list), explored set, frontier\_set
    \item \textbf{Successor order:} Pushes in reverse (L→M→R) so pop() yields R→M→L
    \item \textbf{Goal detection:} Terminates on first solution found (may be deep/suboptimal)
\end{itemize}

\paragraph{Theoretical Properties.}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Completeness:} Not complete without depth control; complete with duplicate detection on finite grids
    \item \textbf{Optimality:} NO --- finds any solution, not necessarily the best
    \item \textbf{Time complexity:} $O(b^m)$ in worst case (can explore unnecessary deep branches)
    \item \textbf{Space complexity:} $O(b \cdot m)$ --- better than BFS
\end{itemize}

\paragraph{Justification for this problem.}
DFS unsuitable for this domain: lacks cost optimization, can find very suboptimal solutions (as confirmed experimentally), and explores deep unproductive branches without heuristic guidance.

\subsection{Heuristic for A*}

\subsubsection{Proposed Heuristic}
$$h(s) = d_{\text{Euclidean}}(s, s_{\text{goal}}) + c_{\text{rotation}}(s, s_{\text{goal}})$$

where:
\begin{align*}
d_{\text{Euclidean}} &= \sqrt{(x_{\text{goal}} - x)^2 + (y_{\text{goal}} - y)^2} \\
c_{\text{rotation}} &= \begin{cases}
\min(|o_{\text{goal}} - o|, 8 - |o_{\text{goal}} - o|) & \text{if } o_{\text{goal}} \neq 8 \\
0 & \text{if } o_{\text{goal}} = 8 \text{ (wildcard)}
\end{cases}
\end{align*}

\subsubsection{Rationale and Justification}

\paragraph{Euclidean distance component:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Represents straight-line distance (shortest geometric path)
    \item Optimistic: assumes direct movement without obstacles
    \item Never overestimates: minimum hardness is 1, so Euclidean $\leq$ real cost
\end{itemize}

\paragraph{Rotation component:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Computes minimum angular distance (circular metric modulo 8)
    \item Exact cost for reaching target orientation (each rotation = 1 unit)
    \item Returns 0 when target orientation is wildcard (code 8)
\end{itemize}

\subsubsection{Admissibility Proof}
The heuristic $h(s)$ is \textbf{admissible} because:
\begin{enumerate}[leftmargin=1.5cm,itemsep=0.1em]
    \item Euclidean distance $\leq$ true movement cost (ignores terrain hardness and assumes straight paths)
    \item Rotation component is exact (neither over nor underestimated)
    \item Sum of two underestimates/exact values $\Rightarrow$ admissible
\end{enumerate}
Thus $h(s) \leq h^*(s)$ (true cost to goal) for all states $s$.

\subsubsection{Monotonicity (Consistency)}
A heuristic is \textbf{monotonic} if $h(n) \leq c(n, a, n') + h(n')$ for all successors $n'$.

\paragraph{Analysis:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Rotations:} $h(n) = d + r$ changes to $h(n') = d + (r \pm 1)$ with cost 1. Satisfies: $d + r \leq 1 + (d + (r-1))$ \checkmark
    \item \textbf{Movements:} Euclidean distance decreases by $\leq$ traveled distance; real cost $\geq 1$. Generally monotonic but not strictly guaranteed when hardness $\gg 1$ and moving away from goal.
\end{itemize}

\paragraph{Importance of monotonicity:}
Guarantees that first expansion finds optimal path (no node reopening), making A* more efficient. Our heuristic is approximately monotonic and performs well in practice.

% ============================================
% RESULTS
% ============================================
\section{Results}

\subsection{Execution Traces on \texttt{exampleMap.txt}}

The example map is a $3 \times 4$ grid with starting position $(0, 3, 0)$ (row 0, column 3, facing North) and goal position $(1, 2, 8)$ where orientation 8 indicates any final orientation is acceptable. Below are the solution traces produced by each algorithm.

\subsubsection{BFS Trace}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Node 0 (starting node)
  (0, 0, START, (0, 3, 0))
Operator 1: rotate_right
Node 1: (1, 1, rotate_right, (0, 3, 1))
Operator 2: move
Node 2: (2, 4, move, (1, 2, 1))
Total explored: 2, Frontier: 2
\end{lstlisting}

\subsubsection{DFS Trace}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Node 0 (starting node)
  (0, 0, START, (0, 3, 0))
Operator 1: rotate_right
Node 1: (1, 1, rotate_right, (0, 3, 1))
Operator 2: move
Node 2: (2, 4, move, (1, 2, 1))
Total explored: 2, Frontier: 1
\end{lstlisting}

\subsubsection{A* Trace}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Node 0 (starting node)
  (0, 0, START, 2.24, (0, 3, 0))
Operator 1: rotate_right
Node 1: (1, 1, rotate_right, 1.65, (0, 3, 1))
Operator 2: move
Node 2: (2, 4, move, 0.00, (1, 2, 1))
Total explored: 2, Frontier: 1
\end{lstlisting}

\subsection{Experimental Performance Analysis}

\subsubsection{Experimental Setup}
Experiments were conducted on randomly generated maps of sizes $3\times3$, $5\times5$, $7\times7$, and $9\times9$. For each size, 5 different random maps were generated with:
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Start position: $(0, 0)$ facing North (orientation 0)
    \item Goal position: $(N-1, N-1)$ with any orientation (wildcard 8)
    \item Terrain hardness: random values between 1 and 9
\end{itemize}

\noindent Results are averaged across the 5 trials per map size.

\subsubsection{Performance Metrics}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{d}: Solution depth (number of actions in path)
    \item \textbf{g}: Solution cost (sum of action costs)
    \item \textbf{\#E}: Number of nodes explored (expanded)
    \item \textbf{\#F}: Final frontier size (nodes in queue when solution found)
\end{itemize}

\subsubsection{Comparative Results}

\begin{table}[H]
\centering
\caption{Results for $3\times3$ maps}
\begin{tabular}{lcccc}
\toprule
\textbf{Algorithm} & \textbf{d} & \textbf{g} & \textbf{\#E} & \textbf{\#F} \\
\midrule
BFS & 5.0 & 10.6 & 10.0 & 5.0 \\
DFS & 16.0 & 25.2 & 18.0 & 8.0 \\
A* & 5.0 & 10.6 & 24.6 & 10.4 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Results for $5\times5$ maps}
\begin{tabular}{lcccc}
\toprule
\textbf{Algorithm} & \textbf{d} & \textbf{g} & \textbf{\#E} & \textbf{\#F} \\
\midrule
BFS & 7.0 & 15.4 & 30.0 & 25.0 \\
DFS & 51.0 & 77.8 & 69.0 & 35.0 \\
A* & 7.0 & 15.4 & 84.6 & 31.4 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Results for $7\times7$ maps}
\begin{tabular}{lcccc}
\toprule
\textbf{Algorithm} & \textbf{d} & \textbf{g} & \textbf{\#E} & \textbf{\#F} \\
\midrule
BFS & 9.0 & 21.0 & 97.0 & 55.0 \\
DFS & 136.0 & 211.0 & 168.0 & 81.0 \\
A* & 10.8 & 20.4 & 181.6 & 53.8 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Results for $9\times9$ maps}
\begin{tabular}{lcccc}
\toprule
\textbf{Algorithm} & \textbf{d} & \textbf{g} & \textbf{\#E} & \textbf{\#F} \\
\midrule
BFS & 11.0 & 27.6 & 225.0 & 87.0 \\
DFS & 207.0 & 319.4 & 239.0 & 144.0 \\
A* & 13.0 & 25.8 & 313.8 & 79.8 \\
\bottomrule
\end{tabular}
\end{table}

% ============================================
% DISCUSSION
% ============================================
\section{Discussion}

\subsection{Comparative Analysis of Implemented Methods}

\subsubsection{Breadth-First Search (BFS)}

\paragraph{Observed Advantages:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Consistently found minimum depth solutions ($d$) across all map sizes
    \item Competitive path costs similar to A* (especially on small maps)
    \item Significantly fewer nodes explored (\#E) than A* in most cases
    \item Controlled frontier growth (\#F smaller than A*)
\end{itemize}

\paragraph{Observed Disadvantages:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Exponential space growth: frontier increased from 5 ($3\times3$) to 87 ($9\times9$)
    \item No cost awareness: optimizes depth, not path cost
    \item Cannot adapt to terrain characteristics
\end{itemize}

\paragraph{Explanation:}
BFS explores systematically level-by-level, guaranteeing minimum-depth solutions. In this domain, shorter paths tend to have reasonable costs because rotations (cost 1) are inexpensive and the robot can choose relatively direct routes.

\subsubsection{Depth-First Search (DFS)}

\paragraph{Observed Advantages:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Relatively compact final frontier: only 8-144 nodes
    \item Simple implementation without priority queues or complex data structures
    \item Linear space complexity in theory
\end{itemize}

\paragraph{Observed Disadvantages:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Dramatically suboptimal solutions: 3-19× worse depth than BFS/A*
    \item Severe quality degradation: depth grew from 16 ($3\times3$) to 207 ($9\times9$)
    \item Higher path costs: 2-12× more expensive than optimal
    \item No quality guarantees whatsoever
\end{itemize}

\paragraph{Explanation:}
DFS blindly explores deep branches without considering proximity to goal. It frequently wanders far from the target, creating unnecessarily long and expensive paths. Results confirm it is completely unsuitable for this navigation problem.

\subsubsection{A* Search}

\paragraph{Observed Advantages:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Cost optimality guaranteed}: found minimum-cost solutions in all experiments
    \item Competitive depth: matched or slightly exceeded BFS depth
    \item Better cost than BFS on large maps: $g=25.8$ vs $27.6$ on $9\times9$
    \item Effective heuristic guidance toward goal
\end{itemize}

\paragraph{Observed Disadvantages:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Explored 2-3× more nodes than BFS on large maps (\#E: 313.8 vs 225.0 on $9\times9$)
    \item Larger frontier maintained during search
    \item Computational overhead: heuristic calculation + heap operations
    \item Explored more unnecessarily on small maps where BFS was sufficient
\end{itemize}

\paragraph{Explanation:}
A* explored more nodes than expected because the Euclidean heuristic significantly underestimates real cost (ignores variable terrain hardness, intermediate rotations, and movement constraints). This causes A* to explore many states that appear promising by $f(n)$ but don't lead to optimal paths. However, admissibility guarantees that the final solution is cost-optimal.

\subsection{Heuristic Performance Analysis}

\paragraph{Positive Aspects:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Admissibility verified}: Found optimal solutions in all experiments
    \item \textbf{Effective direction}: Successfully guided search toward goal
    \item \textbf{Rotation awareness}: Including orientation cost improved estimates
    \item \textbf{Computational efficiency}: Fast to calculate ($O(1)$ per state)
\end{itemize}

\paragraph{Limitations Observed:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Excessive underestimation}: Led to 2-3× more exploration than BFS
    \item \textbf{Ignores terrain costs}: Assumes minimum hardness of 1 (real values 1-9)
    \item \textbf{No intermediate rotations}: Doesn't account for turns needed during movement
    \item \textbf{Straight-line assumption}: Impossible with 8-directional discrete movement
\end{itemize}

\paragraph{Comparative Insight:}
The surprising result that BFS explored fewer nodes than A* demonstrates that a poorly-informed heuristic can be worse than blind search. However, A* maintains its critical advantage: \textit{guaranteed cost optimality}, which BFS cannot provide.

\subsection{Extension: Impassable Rocks}

\subsubsection{Problem Representation}
\textbf{Map encoding:} Use special value (e.g., 0 or -1) to mark impassable cells, or very high cost ($\infty$).

\textbf{Operator modification:} The \texttt{move} action requires additional precondition:
$$\text{precondition}(\text{move}) = (0 \leq x' < N) \land (0 \leq y' < M) \land (\text{hardness}(x', y') \neq \text{IMPASSABLE})$$

\subsubsection{Impact on Problem Characteristics}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Complexity increase}: Robot must navigate around obstacles, increasing path length
    \item \textbf{Potential incompleteness}: Goal may be unreachable if completely blocked
    \item \textbf{Reduced branching}: Effective branching factor $b$ decreases near obstacles
    \item \textbf{State space reduction}: Fewer reachable states
\end{itemize}

\subsubsection{Heuristic Validity}
\paragraph{Euclidean heuristic:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{Remains admissible}: Straight-line still underestimates (optimistic)
    \item \textbf{Less informed}: May point directly through obstacles, misleading search
    \item \textbf{Increased exploration}: A* will explore more nodes around barriers
\end{itemize}

\paragraph{Improvement --- Obstacle-aware heuristic:}
Precompute true distances ignoring orientation using Dijkstra from goal backwards. More expensive but significantly more informed.

\subsubsection{Algorithm Suitability}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \textbf{BFS:} Remains complete; still not cost-optimal
    \item \textbf{DFS:} Requires depth limit (IDDFS) to guarantee completeness; still not optimal
    \item \textbf{A*:} \textit{Best choice} --- maintains completeness and cost optimality despite reduced efficiency
\end{itemize}

\paragraph{Conclusion:}
With impassable obstacles, A* becomes the clearly superior choice as it's the only algorithm guaranteeing both solution completeness and cost optimality.
\newpage
% ============================================
% APPENDIX
% ============================================
\appendix
\section{Source Code Documentation}

\subsection{Overview of Implementation}
The implementation consists of 5 main Python modules:
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \texttt{state.py}: State representation (frozen dataclass)
    \item \texttt{node.py}: Search tree node with path reconstruction
    \item \texttt{problem.py}: Problem specification (successors, goal test, map loading)
    \item \texttt{search.py}: Implementation of BFS, DFS, and A* algorithms
    \item \texttt{main.py}: Command-line interface for running experiments
\end{itemize}

\noindent Additionally, \texttt{run\_experiments.py} automates performance testing on random maps.

% ============================================
% STATE.PY
% ============================================
\subsection{State Representation (\texttt{state.py})}

\paragraph{Purpose:} Defines the state space representation using an immutable dataclass.

\paragraph{Key design decisions:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \texttt{frozen=True}: Makes states hashable for use in sets/dicts (explored, frontier)
    \item \texttt{slots=True}: Reduces memory overhead (important for large state spaces)
    \item Compact \texttt{\_\_str\_\_}: Human-readable output for debugging/traces
\end{itemize}


% ============================================
% NODE.PY
% ============================================
\subsection{Search Node (\texttt{node.py})}

\paragraph{Purpose:} Represents nodes in the search tree with parent pointers for path reconstruction.

\paragraph{Key attributes:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \texttt{state}: Current state (position + orientation)
    \item \texttt{parent}: Link to parent node for backtracking
    \item \texttt{op}: Action taken to reach this node
    \item \texttt{g}: Accumulated path cost from root
    \item \texttt{depth}: Number of actions from root
\end{itemize}

\paragraph{Methods:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \texttt{path()}: Traces parent pointers to root, returns solution path
    \item \texttt{\_\_lt\_\_}: Dummy comparison for heap tie-breaking (uses counter instead)
\end{itemize}

% ============================================
% PROBLEM.PY
% ============================================
\subsection{Problem Specification (\texttt{problem.py})}

\paragraph{Purpose:} Centralizes problem definition: successor generation, goal testing, and map I/O.

\paragraph{Key components:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item \texttt{MOVES}: Global array mapping orientations to $(\Delta x, \Delta y)$ displacements
    \item \texttt{load\_map()}: Parses map file (dimensions, terrain matrix, start/goal states)
    \item \texttt{successors()}: Generates valid successors in fixed R$\to$M$\to$L order
    \item \texttt{is\_goal()}: Checks goal satisfaction (handles orientation wildcard)
\end{itemize}

\paragraph{Design rationale:}
Centralizing \texttt{successors()} ensures all algorithms (BFS, DFS, A*) explore in consistent order, enabling fair comparison.

% ============================================
% SEARCH.PY - BFS
% ============================================
\subsection{Breadth-First Search (\texttt{search.py})}

\paragraph{Implementation highlights:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Uses \texttt{collections.deque} for efficient $O(1)$ append/popleft
    \item \texttt{frontier\_set} provides $O(1)$ duplicate checking (avoids linear search)
    \item \texttt{explored} set prevents state re-expansion
    \item Goal check on generation (not expansion) for early termination
    \item Verbose mode provides step-by-step execution trace
\end{itemize}

\paragraph{Complexity:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Time: $O(|V| + |E|)$ where $|V| = N \times M \times 8$, $|E| \leq 3|V|$
    \item Space: $O(b^d)$ for frontier storage
\end{itemize}

% ============================================
% SEARCH.PY - A*
% ============================================
\subsection{A* Search (\texttt{search.py})}

\paragraph{Implementation highlights:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Uses \texttt{heapq} for priority queue (min-heap by $f(n) = g(n) + h(n)$)
    \item \texttt{itertools.count()} for tie-breaking (FIFO when $f$ values equal)
    \item \texttt{frontier\_best} dict tracks best $g$ per state (lazy deletion)
    \item Stale entry detection: skips outdated heap entries
    \item \texttt{explored} dict maps states to best-known $g$ values
\end{itemize}

\paragraph{Heuristic function:}
Euclidean distance + minimum rotation cost. Admissible and consistent. Fast $O(1)$ computation per state.

\paragraph{Complexity:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Time: $O(|E| \log |V|)$ due to heap operations
    \item Space: $O(|V|)$ for frontier and explored sets
\end{itemize}

% ============================================
% MAIN.PY
% ============================================
\subsection{Main Program (\texttt{main.py})}

\paragraph{Purpose:} Command-line interface for running search algorithms on map files.

\paragraph{Features:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Accepts algorithm choice (bfs, dfs, astar) via command line
    \item Optional verbose mode for detailed execution traces
    \item Outputs solution path with node details
    \item Reports explored and frontier statistics
\end{itemize}

% ============================================
% RUN_EXPERIMENTS.PY
% ============================================
\subsection{Experiment Automation (\texttt{run\_experiments.py})}

\paragraph{Purpose:} Automates performance testing on randomly generated maps.

\paragraph{Features:}
\begin{itemize}[leftmargin=1.5cm,itemsep=0.1em]
    \item Generates random maps of configurable sizes (3$\times$3, 5$\times$5, 7$\times$7, 9$\times$9)
    \item Runs all three algorithms (BFS, DFS, A*) on each map
    \item Collects statistics: depth, cost, nodes explored, frontier size
    \item Averages results over multiple trials (default: 5 per size)
    \item Outputs formatted LaTeX tables for report integration
\end{itemize}

\end{document}
